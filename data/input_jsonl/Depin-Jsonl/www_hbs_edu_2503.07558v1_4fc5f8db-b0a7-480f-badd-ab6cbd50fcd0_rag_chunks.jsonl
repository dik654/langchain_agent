{"text": "Incentive-Compatible Recovery from Manipulated Signals, with Applications to Decentralized Physical Infrastructureâˆ— Jason Milionisâ€  Jens Ernstbergerâ€¡ Joseph BonneauÂ§ Scott Duke KominersÂ¶ Tim Roughgardenâ€– Initial version: February 3, 2025 Current version: March 4, 2025 Abstract2025 We introduce the first formal model capturing the elicitation of unverifiable information from a party (the â€œsourceâ€) with implicit signals derived by other players (the â€œobserversâ€). Our model is motivated in part by applications in decentralized physical infrastructure networks (a.k.a.Mar â€œDePINâ€), an emerging application domain in which physical services (e.g., sensor information, 10 Abandwidth,key challengeor energy)in thesearesignalprovidednetworkat leastapplicationsin part byis verifyinguntrustedtheandlevelself-interestedof service thatparties.was actually provided by network participants. We first establish a condition called source identifiability, which we show is necessary for the existence of a mechanism for which truthful signal reporting is a strict equilibrium. For a converse, we build on techniques from peer prediction to show that in every signal network that satisfies the source identifiability condition, there is in fact a strictly truthful mechanism, where[cs.GT] truthful signal reporting gives strictly higher total expected payoff than any less informative equilibrium. We furthermore show that this truthful equilibrium is in fact the unique equilibrium of the mechanism if there is positive probability that any one observer is unconditionally honest (as would happen, for example, if an observer were run by the network owner). Also, by extending our condition to coalitions, we show that there are generally no collusion-resistant mechanisms in the settings that we consider. We apply our framework and results to two DePIN applications: proving location, and proving bandwidth. In the location-proving setting observers learn (potentially enlarged) Euclidean distances to the source. Here, our condition has an appealing geometric interpretation, implying that the sourceâ€™s location can be truthfully elicited if and only if it is guaranteed to lie inside the convex hull of the observers. In the bandwidth-proving setting, we consider observers that receive noisy (and possibly throttled) evaluations of a sourceâ€™s bandwidth; we show that our mechanism gives a quasi-strict truthful equilibrium, meaning that the source is disincentivized from reporting a larger bandwidth than they have available.arXiv:2503.07558v1 âˆ—Milionisâ€™s research is supported in part by NSF awards CNS-2212745, CCF-2332922, CCF-2212233, DMS-2134059, and CCF-1763970, by an Onassis Foundation Scholarship, and an A.G. Leventis educational grant. Kominers gratefully acknowledges support from the Digital Data Design D3 Institute at Harvard and the Ng Fund and the Mathematics in Economics Research Fund of the Harvard Center of Mathematical Sciences and Applications. Roughgardenâ€™s research at Columbia University is supported in part by NSF awards CCF-2006737 and CNS-2212745. Bonneau, Kominers, and Roughgarden hold positions at a16z crypto (for general a16z disclosures, see https://www.a16z.com/disclosures/). Milionis and Ernstberger performed work in part during an internship at a16z crypto. Notwithstanding, the ideas and opinions expressed herein are those of the authors, rather than of a16z or its affiliates. Kominers and Roughgarden also advise companies on marketplace and incentive design. â€ Columbia University. Email: jm@cs.columbia.edu â€¡Technical University of Munich. Email: jens.ernstberger@gmail.com Â§New York University, and a16z crypto. Email: jb6395@cs.nyu.edu Â¶Harvard Business School, Harvard University, and a16z crypto. Email: kominers@fas.harvard.edu â€–Columbia University, and a16z crypto. Email: tim.roughgarden@gmail.com", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 1, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p1_c1", "creationDate": "D:20250311022544Z"}}
{"text": "1 Introduction 1.1 Sources, Observers, and Manipulated Signals We consider a mechanism designer interested in eliciting information ğ‘¥, drawn from some abstract set ğ’³, known to a self-interested agent that we call the source. We assume that the designer cannot directly verify the accuracy of a self-report ^ğ‘¥âˆˆğ’³by the source, but can instead rely also on the reports ^ğ‘¦= ^ğ‘¦1, . . . , ^ğ‘¦ğ‘›of ğ‘›â‰¥2 self-interested observers that receive signals ğ‘¦related to ğ‘¥. We allow the source to manipulate the distribution from which observersâ€™ signals are drawn. For example, ğ‘¥could represent the true location of an object of interest and ^ğ‘¥the alleged location of that object (as reported by its owner, for example). Each observer ğ‘–could represent a sensor, with ğ‘¦ğ‘–being that sensorâ€™s estimate of its distance from the object, as measured e.g. by the empirical round-trip time of communicating with it. The object may be able to manipulate observersâ€™ distance estimates, for example by deliberately delaying before responding to communication requests. The primary goal of the paper is to characterize when this mechanism problemâ€”the incentive- compatible recovery of the sourceâ€™s information from the (possibly manipulated and/or misreported) signals received by the mechanismâ€”is solvable. More precisely, we ask: 1. Under what condition(s) on the allowable source manipulations does there exist a prior-free mechanism for which truthful behavior is a strict Bayesian Nash equilibrium? 2. Under what conditions can the truthful equilibrium be made unique? And conversely: 3. Under what conditions is such a mechanism impossible? Our study is motivated in part by applications in decentralized physical infrastructure networks (a.k.a. â€œDePINâ€), an emerging application domain in which physical services are provided at least in part by untrusted and self-interested parties. A key challenge in such applications is how to verify the level of service that was actually provided by participants. The location-elicitation problem outlined above is a canonical DePIN application, which arises, for example, in contexts such as verifying that a resource like server or processing capacity is geographically distributed (which is important for robustness to local shocks such as weather events), as well as for confirming that decentralized data collection entities such as weather trackers are in the right place. Another canonical DePIN application is the elicitation of a sourceâ€™s available bandwidth, based on noisy measurements taken by observers that may have been manipulated by the source artificially throttling its bandwidth. We stress, however, that the model introduced in this paper is general and is not overly tailored to DePIN applications. For example, the following problem is isomorphic to the above bandwidth- elicitation problem: elicit the true â€œqualityâ€ of a candidate (student, job applicant, etc.) from noisy measurements by observers (letters of recommendation, references, etc.) that may have been manipulated in certain ways by the candidate (e.g., the candidate misrepresenting their abilities to the observers). 1.2 Our Contributions On the modeling and analysis side, our primary contributions are the following: 2", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 2, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p2_c1", "creationDate": "D:20250311022544Z"}}
{"text": "â€¢ We introduce a novel information elicitation problem, with the key feature that the desired information is known solely to one self-interested agent (the source) who can both misreport that information and manipulate the distribution over the correlated signals observed by other agents. â€¢ We provide a sharp characterization of when truthful elicitation is possible in this setting: if and only if an intuitive condition that we call source identifiability holds. Intuitively, source identifiability asserts that the sourceâ€™s true information could in principle be recovered from an infinite number of samples from the manipulated signal distribution. In concrete examples, source identifiability translates to usable guidelines in practice. â€¢ We prove that whenever source identifiability fails to hold, there is no mechanism for which truthful signal reporting is a strict equilibrium. â€¢ When the source identifiability condition holds, meanwhile, we build on techniques from peer prediction to design a signal elicitation mechanism for which truthful reporting is a strictly optimal equilibrium for network participants, in the sense that any less informative equilibrium has strictly lower total expected payoff than is achieved under truthful signal reporting. â€¢ Our mechanismâ€™s guarantee is even stronger when at least one observer is unconditionally honest with positive probabilityâ€”in that case, the truthful, value-maximizing equilibrium is unique. â€¢ We extend our characterization through source identifiability to coalitions, and as a consequence show that there are generally no collusion-resistant mechanisms in the settings that we consider. On the applied side, our work isâ€”to our knowledgeâ€”the first to take DePIN signal elicitation seriously as an incentive design problem. Existing DePIN frameworks have effectively ignored incen- tive issues by either simply assuming truthful reporting, or through out-of-mechanism procedures for resolving reporting issues through governance or audits. Our model and results offer a number of insights into DePIN applications: â€¢ We use our general results to characterize when truthful signal elicitation is possible in location signal networks and bandwidth signal networks. These two DePIN categories are actively used in practice (see, e.g., Sheng et al. 2024b; Sheng et al. 2024a), and our results imply crucial design considerations for setting them up, as well as how signal elicitation should be conducted once these networks are deployed. â€¢ In the location-proving setting, observers learn (potentially enlarged) Euclidean distances to the source. Here, the source identifiability condition has an appealing geometric interpretation, implying that the sourceâ€™s location can be truthfully elicited if and only if it is guaranteed to lie inside the convex hull of the observers. In other words, for incentive-compatible location recovery, be sure to â€œsurroundâ€ with observers the possible locations of the object of interest. â€¢ In the bandwidth-proving setting, we consider observers that receive noisy (and possibly throttled) evaluations of a sourceâ€™s bandwidth; we show that our mechanism gives a quasi- strict truthful equilibrium, meaning that the source is disincentivized from reporting a larger bandwidth than they have available. 3", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 3, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p3_c1", "creationDate": "D:20250311022544Z"}}
{"text": "â€¢ Our result on equilibrium uniqueness under a mild unconditional hosesty assumption speaks to and reinforces the importance of â€œdecentralizationâ€ in DePIN: this assumption seems particularly likely to hold in a large decentralized setting because because when there are many independent agents, there is a nontrivial possibility that at least one of them is not compromised; hence, in a well organized, (sufficiently) decentralized physical infrastructure network, the mere threat of being compared against an honest agent induces coordination on a truthful revelation equilibrium. â€¢ Our impossibility result for collusion-resistant mechanisms (e.g., in settings where an agent can, through sybils, act as both a source and an observer) can be interpreted as the first formal treatment of what is known as the â€œself-dealingâ€ problem in DePIN. Our result implies that self-dealing must be handled through out-of-mechanism means, such as restrictions on permissionless entry, further refined trust assumptions, or both. More broadly, our work here shows that DePIN networks are some of the largest and most natural applications for peer prediction and related techniques to ever arise â€œin the field.â€ 1.3 Related work Our work relates to the active and expansive body of work on peer prediction mechanisms (Prelec 2004; Miller et al. 2005; Witkowski and Parkes 2012; Zhang and Chen 2014; Waggoner and Chen 2013; Prelec 2021; Schoenebeck and Yu 2023; Kong and Schoenebeck 2019; Radanovic and Faltings 2014; Kong et al. 2020; Richardson and Faltings 2024). A core difference relative to the peer prediction setting is that, in our work, the source is allowed to actively manipulate the other playersâ€™ observed signals before those signals are elicited.1 Most mechanisms for the truthful elicitation of unverifiable information are surprisingly brittle (sensitive) to a number of assumptions; restrictive assumptions have been usually placed on the information structure, population size, signal spaces, and whether the mechanism is aware of the settingâ€™s joint distribution (Zhang and Chen 2014; Schoenebeck and Yu 2023). Currently, the peer prediction mechanisms with the most minimal set of assumptions to obtain ex-ante Pareto dominance to any uninformative equilibrium and strong truthfulness respectively have been given by Schoenebeck and Yu (2023) and Prelec (2021) correspondingly. The former uses a stochastically relevant setting about signals received from individuals by the nature, and the latter requires a stronger assumption than stochastic-relevance of signals, specifically second-order stochastic relevance about how oneâ€™s posterior distribution about another playerâ€™s signal changes, using a third playerâ€™s (truthful) signal. Generic impossibilities in peer prediction regimes with few assumptions have been given by Waggoner and Chen (2013) and Zhang and Chen (2014); our technique for proving impossibility in non-source-identifiable model specifications is inspired by their general ideas. In the multiple-questions peer prediction regime, to obtain truthfulness, agents are asked to report on multiple correlated tasks (Dasgupta and Ghosh 2013; Shnayder et al. 2016). Alternatives 1While the possibility of the source manipulating observersâ€™ signals has not been considered in the peer prediction literature, it does seem plausible that it would be a concern in some settings in which peer prediction is used in practice. For example, in settings like that of Hussam et al. (2022) where peer prediction is used to elicit the ability of microentrepreneurs from assessments by their neighbors, we might imagine that, prior to participating in the peer prediction mechanism, individuals would invest effort in convincing their neighbors that they are especially effective at innovating and/or making efficient use of capital. In this sense, our work suggests how to augment the traditional goals of peer prediction mechanism design to address a practical robustness concern that is typically left outside the boundaries of that model. 4", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 4, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p4_c1", "creationDate": "D:20250311022544Z"}}
{"text": "to this method including estimating the ground truth (Han et al. 2023), including with the help of machine learning techniques, thereby almost making the problem one where partial access to the ground truth can be granted. Relatedly, our unconditional honesty extension bears a semblance to an observation by Gao et al. (2020) that in costly information-gathering scenarios (such as peer grading where effort has to be exerted) comparison to the ground truth with low probability is sufficient to yield a truthful elicitation mechanism; in their work, the trusted evaluator that provides an unbiased estimator of the ground truth is known in advance. The role of the possibility of an unconditional observer in equilibrium selection is reminiscent of the role of â€œcommitment typesâ€ in reputation games (see, e.g., Fudenberg and Maskin 1986; Jaramillo and Srikant 2010, as well as Levin 2006 and the references therein), although in our setting, the commitment type disciplines behavior in a single-shot mechanism rather than in a repeated game where a reputation for commitment can be observed over time. Likewise, the need for the signal structure to be refined enough to render different strategies probabilistically distinguishable appears in various forms throughout game theory; for example, such a condition is used in characterizing when cooperation is possible in repeated games with imperfect public monitoring (Fudenberg et al. 2009; Abreu et al. 1990). The nascent literature on Decentralized Physical Infrastructure Networks (DePIN) has studied Byzantine (i.e., arbitrary adversarial) behavior in information elicitation systems, with a focus on setting limits on the fraction of the population that can be Byzantine, and assuming that the rest are unconditionally honest, without the consideration of any incentives (Sheng et al. 2024a; Maram et al. 2021; Sheng et al. 2024b). Our work here crucially differs in that we study the playersâ€™ rational behavior according to utility functions. Sheng et al. (2024a) and Sheng et al. (2024b) study the respective settings of location and bandwidth capacity elicitation with this in mind. Both Sheng et al. (2024a) and likewise Maram et al. (2021) substantiate the practicality of using (possibly enlarged by manipulation) distances as a relevant assumption in the setting of location verification, and treat players as non-strategic; instead, the former is based on the adversarial model and performs Byzantine-resistant triangulation, while the latter considers the servers trustworthy in their timestamping. We formally study how incentives play out with such mechanisms, and thus achieve a great synergy with high practical relevance. Goel et al. (2021), motivated in part by the design of decentralized oracle networks, give a non-strongly-truthful peer prediction mechanism in a setting with subjective, correlated beliefs when there are binary observations. The key novelty in the model of Goel et al. (2021) is the assumption that agents face some outside incentive to misreport (which depends on the aggregate outcome), and the paper focuses on how to adapt mechanisms for peer consistency (Faltings and Radanovic 2017) and use suitable side payments between agents to overcome these incentives; the paper also derives stronger results under assumptions about the number of agents that are unconditionally honest. Zhao et al. (2024) study the specific homogeneous partially-verifiable setting of proof verification, where the status of a common object (the â€proofâ€) can be obtained by players exerting costly effort, and implement a peer prediction mechanism to address rational verifier apathy (in a blockchain context, the â€verifierâ€™s dilemmaâ€); in our setting, the model is built on the presumption of manipulability of signals received by participants. 5", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 5, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p5_c1", "creationDate": "D:20250311022544Z"}}
{"text": "2 Setting In this section, we will introduce the model along with our definitions. Unless otherwise explicitly specified (e.g., when we will be discussing robustness to coalitions), all agents are assumed rational and risk-neutral. Among all players, there is one agent (the source) which has a distinguished role, in that we are interested to elicit her (unverifiable) private information from her interaction with the rest of the players in the game induced by the mechanism. The rest of the players have the role of observers which interact with the source and the mechanism, as described informally in Section 1. 2.1 The basic model A complete description of the model follows: 1. Nature chooses, from a joint prior distribution, the sourceâ€™s signal ğ‘¥âˆˆğ’³and ğ‘›(private) observersâ€™ characteristics {ğ‘ğ‘–}.2 2. The source chooses an ğ‘›-dimensional distribution ğ’Ÿeither from ğ¿ğ‘¥, where ğ¿ğ‘¥is a feasible set of distributions of reports (according to application-specific modeling), or any other distribution that does not correspond to any feasible distribution if the source were truthful. Formally, the source chooses ğ’Ÿâˆˆğ¿ğ‘¥âˆª {ï¸^ğ’Ÿ| âˆ€ğ‘¥âˆˆğ’³: ^ğ’ŸÌ¸âˆˆğ¿ğ‘¥ }ï¸. We denote by ğ¿the multi-valued function defined by ğ‘“(ğ‘¥) â‰œğ¿ğ‘¥wherever the context is clear, and we term ğ¿the model specification. 3. Nature chooses ğ‘¦âˆ¼ğ’Ÿ, and each ğ‘¦ğ‘–gets sent to every one of the ğ‘›observers (each one privately observes their own signal). The observers and source then participate in a mechanism ğ‘€, with common knowledge of all information above, including the model specification ğ¿. This model allows potentially for the source to pick among adversarial values, if the distributions belonging to each ğ¿ğ‘¥are modeled as point masses. In that special case, the set of distributions is then a set of points, out of which the source may choose their favorite one. Note that in this paper we will consider discrete signal spaces. Our work can be generalized to continuous signal spaces by using techniques in a similar fashion to Schoenebeck and Yu (2023), Radanovic and Faltings (2014), and Richardson and Faltings (2024). We move on to define our condition (Definition 1) that we will tie to the existence of a mechanism where signal-truthfulness is a strict Bayesian Nash equilibrium. We use the standard definitions for the Bayesian Nash equilibrium in games with incomplete information. Definition 1 (Source identifiability). A source in a model specification ğ¿is called identifiable if for any two different ğ‘¥1 Ì¸= ğ‘¥2, ğ¿ğ‘¥1 âˆ©ğ¿ğ‘¥2 = âˆ…, i.e., there exists no distribution thatâ€™s exactly the same for two different source signals. Equivalently, a source is identifiable if and only if the multi-valued function defined by ğ‘¥â‡’ğ¿ğ‘¥is injective. We call this property identifiability, because in line with statistics, it roughly implies that the modelâ€™s parameters can be uniquely determined from the probability distribution of the observed 2Our mechanism will be independent of this distribution (i.e., prior-free). Bayesian Nash equilibria of the mechanism are with respect to this prior. We assume that ğ‘¥can take on at least two different values and that ğ‘›â‰¥2. 6", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 6, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p6_c1", "creationDate": "D:20250311022544Z"}}
{"text": "data. In other words, if one could somehow perfectly observe the true data-generating processâ€”e.g., with an infinite amount of dataâ€”they would be able to uniquely deduce the value of the parameter from that distribution. Thus, our mechanismâ€™s intuition is to make use of strictly proper scoring rules to ensure that we can truthfully obtain the sourceâ€™s value, given the rational observers are honest in their signal reporting. We stress that Definition 1 allows for distributions in two different sets ğ¿ğ‘¥1 and ğ¿ğ‘¥2 that are arbitrarily close to each other (e.g., in total variation distance), and only forbids identical distributions. 2.2 Example: proof of location One example we referred to in Section 1 was location verification. We can now see how this maps to the formalism in our model, in the following way: Suppose that both the source and observers are located somewhere on the plane. The observersâ€™ locations on the plane are known and in our model, correspond to vectors ğ‘ğ‘–âˆˆR2. The mechanism designerâ€™s objective is to estimate the (a priori unknown) location of the source, which is going to be ğ‘¥âˆˆR2. Observers gather information from the source, which consist of positive numbers ğ‘¦ğ‘–that are interpreted as the distances between observer ğ‘–and the source. For this example, we suppose that the source can misrepresent its distance to each observer, but can only artificially increase its distance to each one individually (e.g., by delaying communications); it cannot make its distance seem smaller than it actually is. In this sense, this example allows arbitrary â€œone-sided manipulationâ€ by the source. This constraint would be represented with our model specification as ğ¿ğ‘¥(the feasible set of reports) being a (possibly uncountable) set of point-mass distributions: the set of all potentially enlarged distances to each observer. The source is therefore able to choose its favorite enlarged distances that each observer individually receives.3 What does Definition 1 translate to in this setting? In Section 5.1, we show that source identifiability translates to a convex hull condition: a sourceâ€™s location is identifiable if and only if all possible locations of the source are contained in the convex hull formed by the observersâ€™ locations.4 This convex hull condition is intuitive andâ€”importantlyâ€”gives guidance for how observers should be positioned in practice. 3 Main results We begin with our impossibility result for a signal-truthful mechanism in the case of a model specification where the source is not identifiable. Theorem 3.1 (Impossibility when source is not identifiable). Given any model specification ğ¿ where the source is not identifiable, i.e., does not satisfy Definition 1, there exists no mechanism ğ‘€taking as input not only the playersâ€™ self-declared ^ğ‘¥, ^ğ’Ÿ, ^ğ‘¦but also the model specification ğ¿, for which signal truthfulness is a strict Bayesian Nash equilibrium. Proof. For the sake of contradiction, assume there was such a mechanism ğ‘€, and that it assigns a payoff ğ‘¢((^ğ‘¥, ^ğ’Ÿ), ^ğ‘¦, ğ¿) to the source. Because the source in ğ¿is not identifiable, there exist ğ‘¥1 Ì¸= ğ‘¥2 and a joint distribution of manipulated observer signals ğ’Ÿsuch that ğ’Ÿâˆˆğ¿ğ‘¥1 âˆ©ğ¿ğ‘¥2. 3The randomization by nature of ğ‘¦âˆ¼ğ’Ÿis meaningless in this example, as every â€œdistributionâ€ is just a point mass. 4For the exact formalism and details, we refer the interested reader to Section 5.1. 7", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 7, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p7_c1", "creationDate": "D:20250311022544Z"}}
{"text": "Since signal truthfulness is a strict Bayesian Nash equilibrium for ğ‘€, call the respective strategy profile functions (ğ‘ 0(Â·), ğ‘ 1(Â·), . . . , ğ‘ ğ‘›(Â·)), where ğ‘ 0 denotes the sourceâ€™s strategy, mapping the private values of each player to their actions in the mechanism (the actions are declaring (^ğ‘¥, ^ğ’Ÿ) for the source and ^ğ‘¦ğ‘–for observer ğ‘–); then, it must be that ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥1,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥1] > ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥2,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥1] (1) ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥2,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥2] > ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥1,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥2] (2) Build the following rogue (i.e., non-truthful) strategy where the source is truthful when its private value is ğ‘¥1 but behaves the same for ğ‘¥2 (obviously the truthful ğ’Ÿ, chosen by the source, is feasible for both signals ğ‘¥1, ğ‘¥2 by the model specification), i.e., ğ‘ â€²0(ğ‘¥2) = (ğ‘¥1, ğ’Ÿ) and otherwise ğ‘ â€²0 is the same as ğ‘ 0. We now prove that, since this gives the same expected payoff to the source (conditioning on ğ‘¥1) as the truthful strategy, the Bayesian Nash equilibrium cannot be strict, which is the contradiction finishing the proof. Indeed, we have that ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥2,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥2] = ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥2,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥1] < ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥1,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥1] = ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥1,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥2] < ğ‘¦âˆ¼ğ’Ÿ[ğ‘¢((ğ‘¥2,E ğ’Ÿ), ğ‘¦, ğ¿)|ğ‘¥2] , which is a contradiction, and where the equalities hold because the conditional distribution ğ’Ÿis the same and the conditioned random variable is independent of the conditioning random variable, and the inequalities are Eqs. (1) and (2) respectively. We move on to the positive results, and give a mechanism to truthfully elicit the unverifiable information of the source and observers, subject to Definition 1. For technical convenience, and without loss of generality, we will also make the following assumption which is roughly stochastic relevance conditioned on the sourceâ€™s truthfulness:5 Assumption 1 (Technical Condition). For any ğ‘¥âˆˆğ’³, distribution ğ’Ÿâˆˆğ¿ğ‘¥, ğ‘–âˆˆ[ğ‘›], and two ğ‘¦ğ‘–Ì¸= ğ‘¦â€²ğ‘–, Pr [ğ‘¦âˆ’ğ‘–|ğ‘¦ğ‘–] Ì¸= Pr [ğ‘¦âˆ’ğ‘–|ğ‘¦â€²ğ‘–] , ğ’Ÿ|ğ‘¦ğ‘– ğ’Ÿ|ğ‘¦â€²ğ‘– i.e., there do not exist two different ğ‘¦ğ‘–Ì¸= ğ‘¦â€²ğ‘–that induce the same conditional distribution (for the truthful ğ‘¥) on the rest of all truthfully-received observersâ€™ signals. Assumption 1 effectively means that ğ‘¦ğ‘–causes the posterior of any observer ğ‘–to change based on the (truthful) value they receive from the source. In most common regimes, such an assumption would hold, for example because the source has non-overlapping sets of ğ‘¦ğ‘–â€™s (c.f., Section 5.1), or because each of the observers obtains an independent estimate centered on the sourceâ€™s quality of service (c.f., Section 5.2). The sub-mechanism that we will use to gather information from the observers about the source belongs to the class of Bayesian Truth Serum (BTS) mechanisms, pioneered by Prelec (2004); we 5Because the elicitation of the sourceâ€™s signal is the final sought-after consequence, our results can be generalized to the case that the technical condition does not hold, and the optimal strategy is a quasi-strict equilibrium where observer ğ‘–submits any ğ‘¦ğ‘–thatâ€”conditioned on the truthful ğ‘¥â€”yields the exact same marginal distribution for the rest of all observers, i.e., the strategy groups the non-distinct (in terms of the joint probability distribution) ğ‘¦ğ‘–â€™s. 8", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 8, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p8_c1", "creationDate": "D:20250311022544Z"}}
{"text": "specifically use one of the mechanisms in Prelec (2021), although we remark that similar theorems to ours could be proven using many other similar mechanisms, developed by Prelec (2021) and Schoenebeck and Yu (2023). The mechanism ğ‘€is presented in Algorithm 1. We denote by 1{ğ´} the indicator function that is 1 if ğ´happens, otherwise 0. Recall that a strictly proper scoring rule is a (potentially extended) real-valued function ğ‘ƒ(ğ’Ÿ, ğ‘¦) that takes as input a probability measure ğ’Ÿand a realized outcome ğ‘¦, and outputs a real number (reward) such that ğ‘¦âˆ¼ğ’Ÿ[ğ‘ƒ(ğ’Ÿâ€²,E ğ‘¦)] â‰¤Eğ‘¦âˆ¼ğ’Ÿ[ğ‘ƒ(ğ’Ÿ, ğ‘¦)] for all distributions ğ’Ÿ, ğ’Ÿâ€² , with equality if and only if ğ’Ÿâ€² = ğ’Ÿ. Algorithm 1: Mechanism ğ‘€run after model with inputs (ğ‘¥, ğ’Ÿ), ğ‘¦âˆ¼ğ’Ÿ 1. Observers submit ^ğ‘¦ğ‘–to the mechanism. 2. The source submits (^ğ‘¥, ^ğ’Ÿ), where ^ğ‘¥âˆˆğ’³, to the mechanism and to the observers. 3. Observers submit ğœ‹ğ‘–âˆˆ(0, 1] and ^ğ‘¥ğ‘–âˆˆğ’³âˆª{âˆ…} to the mechanism. 4. Each observer ğ‘–is paired (by the mechanism) with a random observer ğ‘—, and submits a probability distribution for ğ‘—â€™s signal to the mechanism.6 The probability distribution is defined by non-negative numbers ^ğ‘ğ‘–(Â·) that sum to 1 across ğ‘—â€™s support of signals. 5. Each observer ğ‘–obtains reward (ï¸ƒ ^ğ‘ğ‘–(^ğ‘¦ğ‘—) )ï¸ƒ (ï¸ƒ ^ğ‘ğ‘—(^ğ‘¦ğ‘–)ğœ‹ğ‘— log âˆ’ 1{^ğ‘¥1 = Â· Â· Â· = ^ğ‘¥ğ‘›} . ğœ‹ğ‘— ^ğ‘ğ‘–(^ğ‘¦ğ‘—)ğœ‹ğ‘– âƒ’âƒ’âƒ’âƒ’âƒ’log )ï¸ƒâƒ’âƒ’âƒ’âƒ’âƒ’+ 6. The source obtains reward ğ‘ƒ(^ğ’Ÿ, ^ğ‘¦) + 1{^ğ‘¥= ^ğ‘¥1 = Â· Â· Â· = ^ğ‘¥ğ‘›} , (3) where ğ‘ƒ(Â·, Â·) is any strictly proper scoring rule. This mechanism is prior-free. Further, the mechanism does not require that ^ğ’Ÿâˆˆğ¿^ğ‘¥, and for this reason is also free of the model specification ğ¿. In other words, the mechanism need not know the model specification at all, and our analysis of the mechanism holds so long as the true (private) signals of the observers indeed come from that model. We next prove a number of desirable properties of this generic mechanism. To state it, we first define the signal-truthful strategy profiles: Definition 2. We call a strategy profile signal-truthful if: 6We note that, per standard procedure in peer prediction mechanisms (see, e.g., Schoenebeck and Yu 2023), one need not ask for an entire probability distribution, but just a single probability (at least in the discrete signals case) by the mechanism choosing a random value as a virtual signal and asking ğ‘–for the probability that ğ‘—â€™s signal is that virtual signal; ğ‘–â€™s reward is then to be modified such that if the randomly chosen signal value matches the actually submitted value from ğ‘—then the normal reward function is followed, otherwise a (maximal) reward of 0 is given. 9", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 9, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p9_c1", "creationDate": "D:20250311022544Z"}}
{"text": "â€¢ The source, given ğ‘¥, chooses ğ’Ÿâˆˆğ¿ğ‘¥,7 and then submits (^ğ‘¥, ^ğ’Ÿ) = (ğ‘¥, ğ’Ÿ). â€¢ Observer ğ‘–, given ğ‘¦ğ‘–, the sourceâ€™s strategy (^ğ‘¥, ^ğ’Ÿ), and pairing ğ‘—, submits ^ğ‘¦ğ‘–= ğ‘¦ğ‘–, ğœ‹ğ‘–= ğ‘Â· ^ğ’Ÿğ‘–(ğ‘¦ğ‘–) (the probability of the marginal on ğ‘–to get ğ‘¦ğ‘–as per ^ğ’Ÿ, rescaled by any 0 < ğ‘â‰¤1 which is fixed across observers), ^ğ‘¥ğ‘–such that ^ğ’Ÿâˆˆğ¿^ğ‘¥ğ‘–(unique by source identifiability) or ^ğ‘¥ğ‘–= âˆ…if none exists, and ^ğ‘ğ‘–(Â·) to be the posterior on ğ‘—â€™s signal conditional on ğ‘¦ğ‘–as per ^ğ’Ÿ. Theorem 3.2 (Truthful equilibrium). For any ğ‘¥âˆˆğ’³(i.e., any prior on ğ’³) and any model specification ğ¿where the source is identifiable as per Definition 1, and subject to Assumption 1, there exists ğ’Ÿâˆˆğ¿ğ‘¥such that for any 0 < ğ‘â‰¤1, the signal-truthful strategy profiles as defined in Definition 2 with the choice of ğ’Ÿare strict Bayesian Nash equilibria of the game induced by the model and the mechanism ğ‘€, where strictness is defined disregarding (i.e., aggregating over) any distribution ğ’Ÿâˆˆğ¿ğ‘¥for the truthful ğ‘¥, for all ğ‘¥âˆˆğ’³.8 Additionally, for any less informative equilibrium of the mechanism, there exists a signal-truthful equilibrium with strictly higher total expected payoff. Proof. First, we prove strict truthfulness. Consider the source and observers separately.9 â€¢ For the source, assuming all observers are truthful (^ğ‘¦= ğ‘¦): the source selects some ğ’Ÿâˆˆ ğ¿ğ‘¥âˆª {ï¸^ğ’Ÿ| âˆ€ğ‘¥âˆˆğ’³: ^ğ’ŸÌ¸âˆˆğ¿ğ‘¥ }ï¸. By the strict properness of scoring rule ğ‘ƒ, the unique best- response is to submit ^ğ’Ÿ= ğ’Ÿ. Because ^ğ’Ÿ= ğ’Ÿ, observers will choose ^ğ‘¥ğ‘–= ğ‘¥for all ğ‘–by Definition 1 if the chosen ğ’Ÿâˆˆğ¿ğ‘¥, otherwise they will choose âˆ…(which is infeasible for the source to report, as itâ€™s the special signal of the observers that the source was not truthful), since (again by source identifiability) there is no other ğ‘¥â€² Ì¸= ğ‘¥that has the same distribution ğ’Ÿ. Strictness for ^ğ‘¥= ğ‘¥follows. â€¢ For observer ğ‘–, assuming all other observers and the source are honest (in particular, this means ^ğ’Ÿ= ğ’Ÿâˆˆğ¿ğ‘¥): first, ^ğ‘¥ğ‘–= ^ğ‘¥is the unique best-response by Definition 1. Second, by the stochastic relevance of Assumption 1 conditioned on the sourceâ€™s truthfulness hence a distribution ğ’Ÿâˆˆğ¿ğ‘¥, the submechanism among the observers operates as a strictly truthful peer prediction mechanism (Prelec 2021). Strict truthfulness for the rest of the strategic choices of observer ğ‘–follows by the basic mechanismâ€™s strict truthfulness. It is left to prove the second part of the theorem. Any less informative equilibrium in ğ‘€exhibits either pooling on ^ğ‘¥= ^ğ‘¥ğ‘–Ì¸= ğ‘¥or is a less informative equilibrium of the sub-mechanism with observers. In the latter case, first consider the associated payoffs of the observers based only on their reports except for ^ğ‘¥ğ‘–â€™s. Applying the data processing inequality twice (see, e.g., Prelec 2021), any signal garbling equilibrium that is less informative (by either randomizing or pooling over a strategy) has strictly less expected payoffs for every observer than the corresponding signal-truthful equilibrium. Therefore, there exists a ğ‘< 1 such that the total expected payoff (including the source) of the corresponding signal-truthful equilibrium is strictly higher. For the former case, we repeat the latter argument, because the equilibrium with ^ğ‘¥= ^ğ‘¥ğ‘–= ğ‘¥is a tie in the individual expected payoffs conditional on each playerâ€™s signals. This proves the second part of the theorem. 7Note that our theorem will state that there exists some ğ’Ÿfor a signal-truthful strategy profile; not all ğ’Ÿâ€™s might correspond to signal-truthful profiles that are strict Bayesian equilibria. 8Recall that this does not detract from signal truthfulness by source identifiability. 9In what follows, because of the aggregating notion of strictness explained in the theoremâ€™s statement, we show that, in the extensive form game, strictness is satisfied disregarding (i.e., conditioning on) the choice ğ’Ÿâˆˆğ¿ğ‘¥that the source makes in the first step of the game before mechanism ğ‘€. 10", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 10, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p10_c1", "creationDate": "D:20250311022544Z"}}
{"text": "A common observation with some peer prediction mechanisms (Schoenebeck and Yu 2023) is that it is sometimes hard to imagine that players would arrive at non-truthful equilibria that require unnatural coordination in their play. In mechanism ğ‘€and any signal-truthful equilibrium, ^ğ’Ÿ= ğ’Ÿ provides a natural point for reports on ^ğ‘¥, ^ğ‘¥ğ‘–to pool on; any other choice of ^ğ’Ÿby the source would in expectation provide them with strictly less payoff, therefore the aforementioned equilibrium could be a natural coordinating strategy profile in the extensive-form game. 4 Extensions 4.1 Unconditional honesty The guarantee of Theorem 3.2 can be sharpened further whenever there is positive probability that at least one observer is unconditionally honest: Lemma 4.1 (Any probability of observer unconditional honesty yields unique truthful equilibrium). If there is a positive probability that any one observer is unconditionally honest, then the truthful equilibrium is the only equilibrium of mechanism ğ‘€. Unconditional honesty of any (random) observer in the game turns the extensive-form game into one where any (other) observerâ€™s information set cannot feasibly have an implicit guarantee around their pairâ€™s behavior given by a Bayesian Nash equilibrium; this is why they must randomize over the (non-trivial) possibility that they get paired with the unconditionally honest observer. It turns out that the mere threat of being matched up to such an observer is enough to deter non-truthful, less-informative equilibria from forming in the game. Thisâ€”along with application of the implications of Theorem 3.2â€”is the reason why the only feasible (unique) equilibrium is the signal-truthful one. Proof of Lemma 4.1. Name the probability ğ‘0 > 0, and say observer ğ‘—is unconditionally honest with probability ğ‘0. Then, by the strictness of the truthful equilibrium in ğ‘€, if observer ğ‘–Ì¸= ğ‘—played any strategy other than the truthful one, then with probability ğ‘0/ğ‘›they would obtain strictly less than the maximal payoff achieved with the truthful strategy (because they got paired with a truthful observer), and with probability 1 âˆ’ğ‘0/ğ‘›they will obtain a payoff that (by the second part of Theorem 3.2) is in expectation less than the truthful one. Thus, by ğ‘0/ğ‘›> 0, an equilibrium is only possible if all observers report truthfully, therefore by strictness of the truthful equilibrium of ğ‘€, the source will also be truthful. The lemma follows. The intuition and formal argument for Lemma 4.1 make it clear that the role that (the possibility of) unconditional honesty plays here reflects a general idea, which we suspect may be useful more broadly: In peer predictionâ€“based mechanisms, agentsâ€™ reports are cross-examined against each otherâ€”and the possibility that at least some agents may be unconditionally honest means that any putative non-truthful equilibrium behavior has some risk of being identified, and punished, through cross-examination with an unconditionally honest agent (who always reports truthfully). Thus, even a small positive probability of an unconditionally honest agent helps isolate the truthful equilibrium. We note also that the assumption that at least one observer might be unconditionally honest is particularly natural in the context of large signal networks with many independent participantsâ€”like in the DePIN applications we examine in Section 5. Indeed, with many independent observers, it becomes increasingly reasonable to assume that the each observer believes that at least one 11", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 11, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p11_c1", "creationDate": "D:20250311022544Z"}}
{"text": "observer may not be compromised. (Moreover, in many applications, it may be possible for the signal networkâ€™s organizer to directly guarantee that at least one observer is unconditionally truthfulâ€”perhaps by managing that observer themself in a way that is common knowledge.) 4.2 Individual rationality In mechanism ğ‘€, with respect to an arbitrary source, the observers can guarantee non-negative expected payoffs if they behave according to a signal-truthful equilibrium as per Theorem 3.2. More specifically, according to straightforward calculations from the mechanismâ€™s payoffs, we note that the expected payoffof ğ‘€to any observer (conditional on their signal) if all observers behave truthfully is non-negative, because it is exactly the Kullback-Leibler divergence between the posterior probability distribution of ğ‘—conditional on ğ‘–â€™s signal and the marginal distribution of ğ‘—â€™s signal according to ğ’Ÿ. This divergence is guaranteed to be non-negative. For the source, the usual comments applicable to affine transformations of scoring rules to guarantee individual rationality hold: for example, if we choose the quadratic scoring rule, then indeed, by adding 1/2 for a transformed scoring rule, the payoff to the source is always non-negative. 4.3 Collusion of source with observers A significant concern in decentralized systems is collusion. A commonly cited reason is that collusion can be readily facilitated with smart contracts that provide the mechanism for parties to coordinate and credibly commit to prescribed behavior. In this section, we will be particularly concerned with collusion of (a subset of) observers with the source, and show that it is essentially impossible for a mechanism to be collusion-resistant and strictly truthful. Definition 3 (Source-observers collusion-resistance). Consider a (specific) subset of observers ğ’âŠ†[ğ‘›] that collude with the source. In our setting, we will call a mechanism ğ’-collusion-resistant, if and only if for any joint (coordinated) reports of the source and subset ğ’, strict truthfulness holds for the sourceâ€™s value, i.e., it is a strict best-response for the source to report its true value to the mechanism. We note that this definition is akin to a quasi-strictness definition, because it aggregates over the actions of the other colluding players in the game induced by the mechanism and the model. Lemma 4.2. Assume that ğ’âŠ†[ğ‘›] is common knowledge to all players and the mechanism. For any model specification ğ¿, consider the following refining as a multi-valued function ğ‘¥â‡’ğ¿ğ‘¥|ğ’â‰œ{ğ’Ÿğ’| ğ’Ÿâˆˆğ¿ğ‘¥}, i.e., every distribution is a marginal of the original model specification over all observers not in the colluding set ğ’. Unless source identifiability holds for the model specification defined by ğ¿|ğ’, there is no mechanism that can be ğ’-collusion-resistant where signal-truthfulness is a Bayesian Nash equilibrium (in the same sense as in Theorem 3.2). Proof. Forward: Construct an instantiation of mechanism ğ‘€(Algorithm 1), where the mechanism only operates over the subset ğ’of all observers that do not collude; the mechanism otherwise ignores (does not request) input from observers in ğ’. By source identifiability on ğ¿|ğ’and Theorem 3.2, the desired properties hold. Reverse: In the framework of our impossibility proof in Theorem 3.1, by the coordination of source and observersâ€™ actions, effectively the actions/reports of players in ğ’are dictated by the source. Therefore, the sourceâ€™s expected payoff ranges only over ğ‘¦ğ’âˆ¼ğ’Ÿğ’for some ğ’Ÿğ’âˆˆğ¿ğ‘¥|ğ’. 12", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 12, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p12_c1", "creationDate": "D:20250311022544Z"}}
{"text": "Now, as in Theorem 3.1, by the sourceâ€™s non-identifiability in ğ¿|ğ’, consider two different ğ‘¥1 Ì¸= ğ‘¥2 for which the conditional distribution can be chosen by the source to be the same, i.e., it holds that ğ’Ÿğ’âˆˆğ¿ğ‘¥1|ğ’âˆ©ğ¿ğ‘¥2|ğ’Ì¸= âˆ…. Following the rest of the expected payoffs gives rise to a similar contradiction like in Theorem 3.1. In the context of decentralized physical infrastructure networks (DePIN), whereby participation to a mechanism on the blockchain is generally permissionless and unconstrained, i.e., new players are free to join the mechanism, one special case of such collusion of a source with a subset of observers is when these â€observersâ€ are the source itself. This is referred to as self-dealing in the context of DePIN, and our Lemma 4.2 above essentially proves that it is impossible to handle, at least in a prior-free mechanism. Thus, we formally prove that self-dealing must be handled out of mechanism, either via restrictions to permissionless entry, further refined trust assumptions, or both. 5 Applications 5.1 Location signal networks Continuing the discussion of location verification we began in Section 2.2, we have that the mechanism designer wants to estimate the sourceâ€™s location, and use the observersâ€™ information gathering to properly incentivize them to conclude the actual sourceâ€™s location. More specifically, ğ‘¥âˆˆRğ‘‘is a vector of a Euclidean space, and each observerâ€™s location is fixed as ğ‘ğ‘–âˆˆRğ‘‘. The model specification consists of (possibly enlarged) distances to the source so long as these are plausibly feasible by some other ğ‘¥â€² âˆˆğ’³in the model, and is given in Environment 1.10 Environment 1 (Location signal network). The sourceâ€™s location is a point ğ‘¥âˆˆğ’³âŠ‚Rğ‘‘. Observers are represented by points ğ‘ğ‘–âˆˆRğ‘‘, and ğ¿ğ‘¥= {{(ğ‘¦1, ğ‘¦2, . . . , ğ‘¦ğ‘›)} | ğ‘¦ğ‘–â‰¥dist(ğ‘ğ‘–, ğ‘¥) âˆ€ğ‘–and âˆƒğ‘¥â€² âˆˆğ’³: âˆ€ğ‘–: ğ‘¦ğ‘–= dist(ğ‘ğ‘–, ğ‘¥â€²)}, i.e., every distribution that belongs to ğ¿ğ‘¥is just a point mass, and feasible reports of the source include all individual values greater than its (minimum) distance to observer ğ‘ğ‘– that are consistent with some feasible ğ‘¥â€² âˆˆğ’³. As a matter of fact, the definition of this model specification means that the source can claim any potentially enlarged distances to observers, not just the plausibly feasible ones. This is because, according to the model description in Section 2, the full set of potential source choices to be revealed to observers, i.e., ğ¿ğ‘¥âˆª {ï¸^ğ’Ÿ| âˆ€ğ‘¥âˆˆğ’³: ^ğ’ŸÌ¸âˆˆğ¿ğ‘¥ }ï¸, includes the full set of strategic choices {{(ğ‘¦1, ğ‘¦2, . . . , ğ‘¦ğ‘›)} | ğ‘¦ğ‘–â‰¥dist(ğ‘ğ‘–, ğ‘¥) âˆ€ğ‘–}.11 Therefore, the source may report any individual values that are larger than the actual distance; of course, by the guarantees of Theorem 3.2, they will only be strictly worse off if they do choose to do so and observers are signal-truthful, if the source is identifiable according to Definition 1. We remark that common alternative noisy models also fall into our framework, e.g., {ï¸ƒ{ï¸ƒ(ğ‘¦1 + ğœ–1, . . . , ğ‘¦ğ‘›+ ğœ–ğ‘›) w.p. 1/2, }ï¸ƒ ğ¿ğ‘¥= ğ‘¥) âˆ€ğ‘–and âˆƒğ‘¥â€² âˆˆğ’³: âˆ€ğ‘–: ğ‘¦ğ‘–= dist(ğ‘ğ‘–, ğ‘¥â€²) . (ğ‘¦1 âˆ’ğœ–1, . . . , ğ‘¦ğ‘›âˆ’ğœ–ğ‘›) w.p. 1/2 }ï¸ƒâƒ’âƒ’âƒ’âƒ’âƒ’ğ‘¦ğ‘–â‰¥dist(ğ‘ğ‘–, 10Everybody knows that the source is somewhere on ğ’³by the common knowledge property. It should not be possible for the source to enlarge their distances such that they claim some ğ‘¥â€² Ì¸= ğ‘¥in order for it to be identifiable, but we include it in the fully general model specification. 11It includes many other possible lies of the source as well, but the particular ones of enlarged distances are of interest, as described in Sections 1 and 2.2. 13", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 13, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p13_c1", "creationDate": "D:20250311022544Z"}}
{"text": "Similar noisy models can represent observers which ping the source and are well-suited to participate in our mechanism, since they can readily provide posterior distributions by virtue of noise estimates from such links they have with the source. Proposition 5.3 gives a sufficient and roughly necessary condition that characterizes the truthful elicitation of the sourceâ€™s location: a mechanism with a strictly truthful Bayesian Nash equilibrium can be given if and only if the source is guaranteed to lie inside the convex hull of the observers. Note that for the necessity, we have to exclude trivially distinguishable cases, such as ğ’³being just two points outside the convex hull on opposite sides of it. To overcome these, since such trivial cases do not add value to the characterization, we require (to prove that the source is not identifiable in these cases) that a non-measure zero (in Rğ‘‘) mass outside of the convex hull is included in ğ’³. In practice, the condition of Proposition 5.3 is very actionable: it indicates that one should think about where the source ğ‘¥might be (in Rğ‘‘), and make sure to â€surroundâ€ it on the perimeter with sensors. We note that in this setting, the sourceâ€™s reward attains a particularly satisfying format: any scoring rule ğ‘ƒ(^ğ’Ÿ, ^ğ‘¦) rewards consistency at the signal-truthful equilibrium; either the vectors obtained by the observers (which according to Proposition 5.3 cannot be manipulated) match exactly the claimed ones by the source (which may be arbitrary, since they donâ€™t need to conform to any guidelines according to the model specification) in which case this component of the sourceâ€™s reward is maximized, or the source does not obtain the maximum reward. In what follows, we denote by Conv({ğ‘1, . . . , ğ‘ğ‘›}) the convex hull defined by the points {ğ‘1, . . . , ğ‘ğ‘›}. We move on with two helpful lemmas about Euclidean spaces, whose proofs we include in Appendix A (Lemma 5.1 concerns the injectivity of exact distances on any domain that is a subset of the convex hull, and Lemma 5.2 is about their distance vectors being coordinate-wise incomparable) that will be used to prove Proposition 5.3. Lemma 5.1. The map ğ‘¥â†¦â†’(dist(ğ‘1, ğ‘¥), . . . , dist(ğ‘ğ‘›, ğ‘¥)) is injective in any domain ğ’³that is a subset of the convex hull Conv({ğ‘1, . . . , ğ‘ğ‘›}). Lemma 5.2. Consider two ğ‘¥â€², ğ‘¥âˆˆConv({ğ‘1, . . . , ğ‘ğ‘›}). If it holds that dist(ğ‘ğ‘–, ğ‘¥â€²) â‰¥dist(ğ‘ğ‘–, ğ‘¥) âˆ€ğ‘–, then ğ‘¥â€² = ğ‘¥. (The converse is trivial, since all distances are the same.) Proposition 5.3 (Convex hull characterization). In the model defined by Environment 1, if ğ’³âŠ†Conv({ğ‘1, . . . , ğ‘ğ‘›}), then the source is identifiable. Conversely, if ğ’³is a superset of a non- measure zero mass of points outside Conv({ğ‘1, . . . , ğ‘ğ‘›}), then the source is not identifiable. Proof. Forward: Recall that we need to show that the multi-valued function ğ‘¥â‡’ğ¿ğ‘¥is injective. As a result of Lemma 5.2, any enlarged distances fall outside of the (truthful) model specification ğ¿ğ‘¥, because they are not plausibly feasible by any other truthful ğ‘¥â€² âˆˆğ’³âŠ†Conv({ğ‘1, . . . , ğ‘ğ‘›}). Therefore, ğ‘¥â‡’ğ¿ğ‘¥corresponds exactly to the map that Lemma 5.1 proves is injective, and this direction is complete. Reverse: If ğ’³is a superset of a non-measure zero set of points outside of Conv({ğ‘1, . . . , ğ‘ğ‘›}), then there are two different ğ‘¥1 Ì¸= ğ‘¥2 âˆˆRğ‘‘and a separating hyperplane from the convex hull (represented by its unit normal vector ğ‘¢âˆˆRğ‘‘) such that âˆ€ğ‘–: âŸ¨ğ‘ğ‘–, ğ‘¢âŸ©â‰¥0 and ğ‘¥1 = âˆ’ğ›¼ğ‘¢, ğ‘¥2 = âˆ’ğ›½ğ‘¢ for some ğ›¼, ğ›½> 0. Without loss of generality, order ğ‘¥1, ğ‘¥2 such that ğ›½> ğ›¼. We show that {(dist(ğ‘1, ğ‘¥2), . . . , dist(ğ‘ğ‘›, ğ‘¥2))} âˆˆğ¿ğ‘¥1 âˆ©ğ¿ğ‘¥2 Ì¸= âˆ…, therefore the source is not identifiable. Indeed, it 14", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 14, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p14_c1", "creationDate": "D:20250311022544Z"}}
{"text": "suffices to prove that âˆ€ğ‘–: dist(ğ‘ğ‘–, ğ‘¥2) > dist(ğ‘ğ‘–, ğ‘¥1).12 This is true by computation, since for any ğ‘–: â€–ğ‘ğ‘–âˆ’ğ‘¥2â€–2 âˆ’â€–ğ‘ğ‘–âˆ’ğ‘¥1â€–2 = (ğ›½âˆ’ğ›¼)(ğ›½+ ğ›¼+ 2âŸ¨ğ‘ğ‘–, ğ‘¢âŸ©) > 0 . 5.2 Bandwidth signal networks In this setting, the mechanism designer wants to elicit the sourceâ€™s (ideally maximum available) bandwidth. Observers obtain noisy and possibly throttled estimates about the sourceâ€™s bandwidth; the model specification is given in Environment 2. A primary rationale for this model specification is the observation that internet connections between two nodes might be throttled, and internet links can operate over multiple hops, therefore even though an observer might have the capacity to notice the full declared bandwidth of the source if connected through a direct peer-to-peer link, they may in fact be connected via a set of intermediate nodes that cannot support this bandwidth. The model, then, would reasonably be expected to be unable to certify a high connection speed, if no observer can witness it. Thus, the model specification below also bakes in the assumption that there is at least one observer capable of probabilistically observing the actual sourceâ€™s bandwidth. Environment 2 (Bandwidth signal network). The sourceâ€™s bandwidth is ğ‘¥âˆˆR+. Given ğ‘¥, every observer obtains independent estimates of the sourceâ€™s bandwidth, coming from distributions whose support is upper bounded (or truncated) at some value thatâ€™s at most ğ‘¥, i.e., ğ¿ğ‘¥= {ğ’Ÿğ‘¥1 Ã— Â· Â· Â· Ã— ğ’Ÿğ‘¥ğ‘›| 0 â‰¤support(ğ’Ÿğ‘¥ğ‘–) â‰¤ğ‘¥âˆ€ğ‘–}, and âˆƒğ’Ÿğ‘¥1 Ã— Â· Â· Â· Ã— ğ’Ÿğ‘¥ğ‘›âˆˆğ¿ğ‘¥such that âˆƒğ‘–: ğ‘¥âˆˆsupport(ğ’Ÿğ‘¥ğ‘–).13 Unfortunately, most settings following Environment 2 are not source-identifiable, as Proposi- tion 5.4 proves. Proposition 5.4. In the model of Environment 2, there is at least one model specification where the source is not identifiable. Proof. There are many example instantiations of the generic model given by Environment 2 that do not satisfy source identifiability. For example, consider the further refined model, where some of the included distributions (letâ€™s denote them by ğ’Ÿğ‘–) in the product distributions contained in ğ¿ğ‘¥(among others) are distributions upper bounded at some fixed value ğ‘ğ‘–, i.e., support(ğ’Ÿğ‘–) â‰¤min{ğ‘ğ‘–, ğ‘¥}. We can model this way the sourceâ€™s choice to artificially throttle the bandwidth that it appears that it has to each of the observers; note that in most realistic regimes, this option is practically available to the source. The source can then (strategically) choose these throttled distributionsâ€”perhaps to its detriment in a system where high bandwidth is incentivized. Formally, for any two different ğ‘¥1, ğ‘¥2 such that ğ‘¥1 > ğ‘¥2 > maxğ‘–âˆˆ[ğ‘›]{ğ‘ğ‘–}, it is clear that {ğ’Ÿ1 Ã— Â· Â· Â· Ã— ğ’Ÿğ‘›} âŠ†ğ¿ğ‘¥1 âˆ©ğ¿ğ‘¥2 Ì¸= âˆ…; hence, the source is not identifiable according to Definition 1. We can now derive a modification of the given guarantees; specifically, we first relax the strictness requirement, as follows. 12Notice that here, the quantifier â€for all ğ‘–â€ is the non-trivial part, and why we use the co-linear vectors ğ‘¥1, ğ‘¥2 with the hyperplaneâ€™s normal vector ğ‘¢. 13This is the condition we impose, because we remind that we consider discrete distributions. Otherwise, we need to impose non-zero measure in a continuous distribution, i.e., ğ’Ÿğ‘¥ğ‘–(ğ‘¥) > 0. 15", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 15, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p15_c1", "creationDate": "D:20250311022544Z"}}
{"text": "Definition 4. A signal-truthful strategy profile of mechanism ğ‘€will be called quasi-strict for the source, if any ^ğ‘¥> ğ‘¥attains strictly less payoff for the source when the observers are following the specified signal-truthful strategies. The relevant lemma follows in Lemma 5.5. Lemma 5.5. For any prior on ğ’³, signal-truthfulness defined by Theorem 3.2 in mechanism ğ‘€, where14 we additionally refine the strategy of every observer by reporting ^ğ‘¥ğ‘–= max {ï¸support(^ğ’Ÿğ‘–)}ï¸ ğ‘– from the received ^ğ’Ÿ, in the setting defined by Environment 2, is quasi-strict for the source, as defined by Definition 4. Proof. Modifying the proof of Theorem 3.2, for the sourceâ€™s strategy only, by strict properness of the scoring rule, itâ€™s still going to be that ^ğ’Ÿ= ğ’Ÿfor some ğ’Ÿâˆˆğ¿ğ‘¥that the source chooses. The source can attain the additional reward of 1 from the indicator function and with every challenger reporting ^ğ‘¥ğ‘–= ğ‘¥according to the signal-truthful Bayesian Nash equilibrium, by choosing ğ’Ÿappropriately, since by Environment 2, âˆƒğ’Ÿâ‰œğ’Ÿğ‘¥1 Ã— Â· Â· Â· Ã— ğ’Ÿğ‘¥ğ‘›âˆˆğ¿ğ‘¥such that âˆƒğ‘–: ğ‘¥âˆˆsupport(ğ’Ÿğ‘¥ğ‘–).15 Thus, any ^ğ‘¥> ğ‘¥will give strictly lower payoff to the source than ğ‘¥, because the indicator will be 0 for any ^ğ‘¥> ğ‘¥, while at ğ‘¥, it will be 1. Acknowledgments The authors thank Pranav Garimidi, Guy Wuollet, and seminar audiences at a16z crypto for helpful comments. 14We need to specify the strategy, because for any given ^ğ’Ÿ, there is no longer a unique ^ğ‘¥ğ‘–such that ^ğ’Ÿâˆˆğ¿^ğ‘¥ğ‘–, due to the source not being identifiable. 15Note that the source might also attain 1 from the indicator function if it chooses some other appropriate ğ’Ÿâˆˆğ¿ğ‘¥, but no such ğ’Ÿâˆˆğ¿ğ‘¥will result in challengers choosing ^ğ‘¥ğ‘–> ğ‘¥at the signal-truthful equilibrium. Rather, challengers might all agree on ^ğ‘¥ğ‘–< ğ‘¥. 16", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 16, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p16_c1", "creationDate": "D:20250311022544Z"}}
{"text": "References Abreu, Dilip, David Pearce, and Ennio Stacchetti (1990). â€œToward a Theory of Discounted Repeated Games with Imperfect Monitoringâ€. In: Econometrica 58.5, pp. 1041â€“1063. issn: 00129682, 14680262. url: http://www.jstor.org/stable/2938299 (visited on 02/11/2025). Dasgupta, Anirban and Arpita Ghosh (2013). â€œCrowdsourced judgement elicitation with endogenous proficiencyâ€. In: Proceedings of the 22nd international conference on World Wide Web, pp. 319â€“ 330. Faltings, Boi and Goran Radanovic (2017). â€œGame theory for data science: Eliciting truthful informationâ€. In: Synthesis Lectures on Artificial Intelligence and Machine Learning 11.2, pp. 1â€“ 151. Fudenberg, Drew, David Levine, and Eric Maskin (2009). â€œThe folk theorem with imperfect public informationâ€. In: A Long-Run Collaboration On Long-Run Games. World Scientific, pp. 231â€“273. Fudenberg, Drew and Eric Maskin (1986). â€œThe Folk Theorem in Repeated Games with Discounting or with Incomplete Informationâ€. In: Econometrica 54.3, pp. 533â€“554. issn: 00129682, 14680262. url: http://www.jstor.org/stable/1911307 (visited on 02/11/2025). Gao, Alice, James Wright, and Kevin Leyton-Brown (July 2020). â€œIncentivizing Evaluation with Peer Prediction and Limited Access to Ground Truth (Extended Abstract)â€. In: Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20. Ed. by Christian Bessiere. Journal track. International Joint Conferences on Artificial Intelligence Organization, pp. 5140â€“5144. doi: 10.24963/ijcai.2020/723. url: https://doi.org/10. 24963/ijcai.2020/723. Goel, Naman, Aris Filos-Ratsikas, and Boi Faltings (2021). â€œPeer-prediction in the presence of out- come dependent lying incentivesâ€. In: Proceedings of the Twenty-Ninth International Joint Con- ference on Artificial Intelligence. IJCAIâ€™20. Yokohama, Yokohama, Japan. isbn: 9780999241165. Han, Yong, Wenjun Wu, Yu Liang, and Lijun Zhang (June 2023). â€œPeer Grading Eliciting Truthfulness Based on Autograderâ€. In: IEEE Trans. Learn. Technol. 16, pp. 353â€“363. issn: 1939-1382. doi: 10.1109/TLT.2022.3216946. url: https://doi.org/10.1109/TLT.2022.3216946. Hussam, Reshmaan, Natalia Rigol, and Benjamin N. Roth (2022). â€œTargeting high ability en- trepreneurs using community information: Mechanism design in the fieldâ€. In: American Eco- nomic Review 112.3, pp. 861â€“898. Jaramillo, Juan JosÂ´e and R. Srikant (2010). â€œA game theory based reputation mechanism to incentivize cooperation in wireless ad hoc networksâ€. In: Ad Hoc Networks 8.4, pp. 416â€“429. issn: 1570-8705. doi: https://doi.org/10.1016/j.adhoc.2009.10.002. url: https: //www.sciencedirect.com/science/article/pii/S1570870509001103. Kong, Yuqing and Grant Schoenebeck (2019). â€œAn information theoretic framework for design- ing information elicitation mechanisms that reward truth-tellingâ€. In: ACM Transactions on Economics and Computation (TEAC) 7.1, pp. 1â€“33. Kong, Yuqing, Grant Schoenebeck, Biaoshuai Tao, and Fang-Yi Yu (2020). â€œInformation elicitation mechanisms for statistical estimationâ€. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. 02, pp. 2095â€“2102. Levin, Jonathan (2006). â€œReputation in Repeated Interactionâ€. In. Maram, Deepak, Iddo Bentov, Mahimna Kelkar, and Ari Juels (2021). â€œGoAT: File geolocation via anchor timestampingâ€. In: Cryptology ePrint Archive. 17", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 17, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p17_c1", "creationDate": "D:20250311022544Z"}}
{"text": "Miller, Nolan, Paul Resnick, and Richard Zeckhauser (2005). â€œEliciting informative feedback: The peer-prediction methodâ€. In: Management Science 51.9, pp. 1359â€“1373. Prelec, DraË‡zen (2004). â€œA Bayesian Truth Serum for Subjective Dataâ€. In: Science 306.5695, pp. 462â€“ 466. doi: 10.1126/science.1102081. eprint: https://www.science.org/doi/pdf/10.1126/ science.1102081. url: https://www.science.org/doi/abs/10.1126/science.1102081. Prelec, Drazen (2021). â€œBilateral Bayesian truth serum: The nxm signals caseâ€. In: Available at SSRN 3908446. Radanovic, Goran and Boi Faltings (June 2014). â€œIncentives for Truthful Information Elicitation of Continuous Signalsâ€. In: Proceedings of the AAAI Conference on Artificial Intelligence 28.1. doi: 10.1609/aaai.v28i1.8797. url: https://ojs.aaai.org/index.php/AAAI/article/ view/8797. Richardson, Adam and Boi Faltings (Mar. 2024). â€œPeer Neighborhood Mechanisms: A Framework for Mechanism Generalizationâ€. In: Proceedings of the AAAI Conference on Artificial Intelligence 38.9, pp. 9883â€“9890. doi: 10.1609/aaai.v38i9.28849. url: https://ojs.aaai.org/index. php/AAAI/article/view/28849. Schoenebeck, Grant and Fang-Yi Yu (2023). â€œTwo strongly truthful mechanisms for three heteroge- neous agents answering one questionâ€. In: ACM Transactions on Economics and Computation 10.4, pp. 1â€“26. Sheng, Peiyao, Vishal Sevani, Ranvir Rana, Himanshu Tyagi, and Pramod Viswanath (2024a). â€œBFT-PoLoc: A Byzantine Fortified Trigonometric Proof of Location Protocol using Internet Delaysâ€. In: arXiv preprint arXiv:2403.13230. Sheng, Peiyao, Nikita Yadav, Vishal Sevani, Arun Babu, Anand Svr, Himanshu Tyagi, and Pramod Viswanath (2024b). â€œProof of backhaul: trustfree measurement of broadband bandwidthâ€. en. In: Proceedings 2024 Network and Distributed System Security Symposium. San Diego, CA, USA: Internet Society. isbn: 9781891562938. doi: 10.14722/ndss.2024.24764. url: https://www.ndss-symposium.org/wp-content/uploads/2024-764-paper.pdf (visited on 02/11/2025). Shnayder, Victor, Arpit Agarwal, Rafael Frongillo, and David C Parkes (2016). â€œInformed truthfulness in multi-task peer predictionâ€. In: Proceedings of the 2016 ACM Conference on Economics and Computation, pp. 179â€“196. Waggoner, Bo and Yiling Chen (2013). â€œInformation elicitation sans verificationâ€. In: Proceedings of the 3rd workshop on social computing and user generated content (SC13). Witkowski, Jens and David C. Parkes (2012). â€œPeer prediction without a common priorâ€. In: Proceedings of the 13th ACM Conference on Electronic Commerce. EC â€™12. Valencia, Spain: Association for Computing Machinery, pp. 964â€“981. isbn: 9781450314152. doi: 10.1145/ 2229012.2229085. url: https://doi.org/10.1145/2229012.2229085. Zhang, Peter and Yiling Chen (2014). â€œElicitability and knowledge-free elicitation with peer predic- tionâ€. In: Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems, pp. 245â€“252. Zhao, Zishuo, Xi Chen, and Yuan Zhou (2024). â€œIt Takes Two: A Peer-Prediction Solution for Blockchain Verifierâ€™s Dilemmaâ€. In: arXiv preprint arXiv:2406.01794. 18", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 18, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p18_c1", "creationDate": "D:20250311022544Z"}}
{"text": "A Proofs Omitted from the Main Text A.1 Proof of Lemma 5.1 Proof. Assume the contrary, i.e., that there are two ğ‘¥, ğ‘¦âˆˆConv({ğ‘1, . . . , ğ‘ğ‘›}) such that ğ‘¥Ì¸= ğ‘¦and âˆ€ğ‘–: dist(ğ‘ğ‘–, ğ‘¥) = dist(ğ‘ğ‘–, ğ‘¦). Rearranging, we obtain â€–ğ‘¥â€–2 âˆ’â€–ğ‘¦â€–2 âŸ¨ğ‘¥âˆ’ğ‘¦, ğ‘ğ‘–âŸ©= = ğ‘, 2 which is a constant independent of ğ‘–. Since ğ‘¥, ğ‘¦are points that belong to the convex hull, there exist ğœ†ğ‘–, ğœ‡ğ‘–â‰¥0 such that âˆ‘ï¸€ğ‘–ğœ†ğ‘–= âˆ‘ï¸€ğ‘–ğœ‡ğ‘–= 1 and ğ‘¥= âˆ‘ï¸€ğ‘–ğœ†ğ‘–ğ‘ğ‘–, ğ‘¦= âˆ‘ï¸€ğ‘–ğœ‡ğ‘–ğ‘ğ‘–. We compute âŸ¨ğ‘¥âˆ’ğ‘¦, ğ‘¥âŸ©= âˆ‘ï¸ ğœ†ğ‘–âŸ¨ğ‘¥âˆ’ğ‘¦, ğ‘ğ‘–âŸ©= ğ‘ âˆ‘ï¸ ğœ†ğ‘–= ğ‘, ğ‘– ğ‘– and similarly âŸ¨ğ‘¥âˆ’ğ‘¦, ğ‘¦âŸ©= ğ‘. Thus, â€–ğ‘¥âˆ’ğ‘¦â€–2 = âŸ¨ğ‘¥âˆ’ğ‘¦, ğ‘¥âˆ’ğ‘¦âŸ©= 0, therefore ğ‘¥= ğ‘¦. This is a contradiction. A.2 Proof of Lemma 5.2 Proof. By ğ‘¥â€² âˆˆConv({ğ‘1, . . . , ğ‘ğ‘›}), there exist ğœ†ğ‘–â‰¥0 such that âˆ‘ï¸€ğ‘–ğœ†ğ‘–= 1 and ğ‘¥â€² = âˆ‘ï¸€ğ‘–ğœ†ğ‘–ğ‘ğ‘–. We calculate â€–ğ‘ğ‘–âˆ’ğ‘¥â€²â€–2 âˆ’â€–ğ‘ğ‘–âˆ’ğ‘¥â€–2 = â€–ğ‘¥âˆ’ğ‘¥â€²â€–2 âˆ’2âŸ¨ğ‘¥âˆ’ğ‘ğ‘–, ğ‘¥âˆ’ğ‘¥â€²âŸ©, and then by weighing and summing the square of all inequalities of the lemmaâ€™s statement, we obtain that âŸ¨ âŸ© 0 â‰¤ âˆ‘ï¸ ğœ†ğ‘– (ï¸ â€–ğ‘ğ‘–âˆ’ğ‘¥â€²â€–2 âˆ’â€–ğ‘ğ‘–âˆ’ğ‘¥â€–2)ï¸ = â€–ğ‘¥âˆ’ğ‘¥â€²â€–2 âˆ’2 ğ‘¥âˆ’ âˆ‘ï¸ ğœ†ğ‘–ğ‘ğ‘–, ğ‘¥âˆ’ğ‘¥â€² = âˆ’â€–ğ‘¥âˆ’ğ‘¥â€²â€–2 , ğ‘– ğ‘– therefore it has to be that ğ‘¥â€² = ğ‘¥, since the square norm is non-negative. 19", "metadata": {"source_file": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "source_full_path": "/home/filadmin/deepseek-RAG/data/downloaded_depin_pdfs/www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0.pdf", "page_number": 19, "chunk_id": "www_hbs_edu_2503.07558v1_4fc5f8db-b0a7-480f-badd-ab6cbd50fcd0_p19_c1", "creationDate": "D:20250311022544Z"}}
