from accelerate import Accelerator
from diffusers import DiffusionPipeline
from fastapi import FastAPI
from pydantic import BaseModel
import torch
from PIL import Image
import base64
import io
import os
from datetime import datetime

# Accelerate ë©€í‹° GPU ì„¤ì •
accelerator = Accelerator()
print("ğŸš€ SD3.5 Medium ëª¨ë¸ ë¡œë”© ì¤‘...")

# ëª¨ë¸ ë¡œë”©
pipe = DiffusionPipeline.from_pretrained(
    "/home/filadmin/ai/models/stable-diffusion-3.5-medium",
    torch_dtype=torch.float16,
    use_safetensors=True,
    local_files_only=True,
    variant="fp16"
)

# accelerateë¡œ í• ë‹¹ëœ ë””ë°”ì´ìŠ¤ì— ëª¨ë¸ ì˜¬ë¦¼
pipe.to(accelerator.device)

print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! Ready on", accelerator.device)

# FastAPI ì„œë²„ ì„¤ì •
app = FastAPI()

# ìš”ì²­ í¬ë§· ì •ì˜
class PromptRequest(BaseModel):
    prompt: str

# ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸
@app.post("/generate")
def generate_image(req: PromptRequest):
    with torch.autocast("cuda"):
        result = pipe(req.prompt).images[0]

    # ì €ì¥ ê²½ë¡œ ìƒì„± (ì˜ˆ: ./outputs)
    os.makedirs("outputs", exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"outputs/{timestamp}.png"
    
    # ì´ë¯¸ì§€ ì €ì¥
    result.save(filename)

    return {
        "status": "ok",
        "prompt": req.prompt,
        "filename": filename,
    }
